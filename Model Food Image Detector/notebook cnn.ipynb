{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP6zWpIFdtWlTIV/Wot7QEg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install tensorflow\n","!pip install matplotlib"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WwMiV2nRhm3y","executionInfo":{"status":"ok","timestamp":1732615175335,"user_tz":-420,"elapsed":7266,"user":{"displayName":"Muhammad Nurkholis M183B4KY2981","userId":"05209614594039969122"}},"outputId":"d95cdbf1-1bce-4b5a-fc11-929d677eeb0f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n","Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers, models\n","import matplotlib.pyplot as plt"],"metadata":{"id":"ooRq0afEhwDp","executionInfo":{"status":"ok","timestamp":1732615186355,"user_tz":-420,"elapsed":4791,"user":{"displayName":"Muhammad Nurkholis M183B4KY2981","userId":"05209614594039969122"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","import zipfile\n","import os\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Path ke file zip di Google Drive\n","# zip_file_path = '/content/drive/MyDrive/cnnmakananbayi/dataset.zip'\n","extract_folder = '/content/drive/MyDrive/cnnmakananbayi/dataset'\n","\n","# # Ekstrak file zip\n","# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","#     zip_ref.extractall(extract_folder)\n","\n","# Cek isi folder\n","os.listdir(extract_folder)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Ah0sdrghxaZ","executionInfo":{"status":"ok","timestamp":1732615221466,"user_tz":-420,"elapsed":17582,"user":{"displayName":"Muhammad Nurkholis M183B4KY2981","userId":"05209614594039969122"}},"outputId":"a9f6299d-d761-4b48-e1de-a48ba600a0b4"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["['train', 'test']"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# from PIL import Image\n","# import os\n","# Tentukan path untuk folder train dan test\n","train_dir = os.path.join(extract_folder, 'train')\n","test_dir = os.path.join(extract_folder, 'test')\n","\n","# def check_and_remove_corrupted_images(folder_path):\n","#     for subdir, _, files in os.walk(folder_path):\n","#         for file in files:\n","#             file_path = os.path.join(subdir, file)\n","#             try:\n","#                 img = Image.open(file_path)\n","#                 img.verify()  # Verifikasi gambar\n","#             except (IOError, SyntaxError) as e:\n","#                 print(f'Removing corrupted image: {file_path}')\n","#                 os.remove(file_path)\n","\n","# # Periksa dan hapus gambar yang korup di folder train dan test\n","# check_and_remove_corrupted_images(train_dir)\n","# check_and_remove_corrupted_images(test_dir)"],"metadata":{"id":"wsPNj7Hbi2Eu","executionInfo":{"status":"ok","timestamp":1732615225602,"user_tz":-420,"elapsed":332,"user":{"displayName":"Muhammad Nurkholis M183B4KY2981","userId":"05209614594039969122"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["\n","# Parameter untuk ImageDataGenerator\n","batch_size = 32\n","img_height = 100\n","img_width = 100\n","\n","# Membuat generator untuk data training\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","# Membuat generator untuk data testing\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","test_generator = test_datagen.flow_from_directory(\n","    test_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SiUYk2oniHGA","executionInfo":{"status":"ok","timestamp":1732615248428,"user_tz":-420,"elapsed":322,"user":{"displayName":"Muhammad Nurkholis M183B4KY2981","userId":"05209614594039969122"}},"outputId":"af2565e2-edf3-47fd-b371-4d4546d1aae8"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 603 images belonging to 25 classes.\n","Found 148 images belonging to 25 classes.\n"]}]},{"cell_type":"code","source":["model = models.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n","    layers.MaxPooling2D(pool_size=(2, 2)),\n","\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D(pool_size=(2, 2)),\n","\n","    layers.Conv2D(128, (3, 3), activation='relu'),\n","    layers.MaxPooling2D(pool_size=(2, 2)),\n","\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(len(train_generator.class_indices), activation='softmax')  # Jumlah kelas\n","])\n","\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wEmLLLSpiMpQ","executionInfo":{"status":"ok","timestamp":1732615259578,"user_tz":-420,"elapsed":313,"user":{"displayName":"Muhammad Nurkholis M183B4KY2981","userId":"05209614594039969122"}},"outputId":"e7950ad4-3f64-4c45-9244-237142cc8fc5"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}]},{"cell_type":"code","source":["!pip install imageio\n","\n","import imageio\n","import os\n","\n","def find_and_remove_corrupted_images(folder_path):\n","    \"\"\"\n","    Finds and removes corrupted images within a given folder and its subfolders using imageio.\n","\n","    Args:\n","        folder_path (str): The path to the folder containing the images.\n","    \"\"\"\n","    for subdir, _, files in os.walk(folder_path):\n","        for file in files:\n","            file_path = os.path.join(subdir, file)\n","            try:\n","                # Attempt to read the image using imageio\n","                _ = imageio.imread(file_path)\n","            except (imageio.core.format.CannotReadFrameError, ValueError) as e:\n","                # If imageio cannot read the image, it's likely corrupted\n","                print(f'Removing corrupted image: {file_path}')\n","                os.remove(file_path)\n","\n","# Assuming 'train_dir' and 'test_dir' are defined as paths to your train and test folders\n","find_and_remove_corrupted_images(train_dir)\n","find_and_remove_corrupted_images(test_dir)"],"metadata":{"id":"k5Ro-rRQmCnp","executionInfo":{"status":"ok","timestamp":1732615530910,"user_tz":-420,"elapsed":259727,"user":{"displayName":"Muhammad Nurkholis M183B4KY2981","userId":"05209614594039969122"}},"outputId":"2ec69742-5dd0-4c0f-c3ed-d6caf2925765","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.36.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.26.4)\n","Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (11.0.0)\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-10-d7ad070b30c5>:18: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n","  _ = imageio.imread(file_path)\n"]}]},{"cell_type":"code","source":["history = model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // batch_size,\n","    epochs=20,  # Sesuaikan jumlah epoch\n","    validation_data=test_generator,\n","    validation_steps=test_generator.samples // batch_size\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vCtqCu1firlY","executionInfo":{"status":"ok","timestamp":1732615921707,"user_tz":-420,"elapsed":390801,"user":{"displayName":"Muhammad Nurkholis M183B4KY2981","userId":"05209614594039969122"}},"outputId":"dfd9cc03-dfa8-4f8a-a29e-9114f45478b0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.0428 - loss: 3.2271 - val_accuracy: 0.1094 - val_loss: 3.0771\n","Epoch 2/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0625 - loss: 3.1561 - val_accuracy: 0.1500 - val_loss: 2.9565\n","Epoch 3/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.1066 - loss: 3.0681 - val_accuracy: 0.1875 - val_loss: 2.8693\n","Epoch 4/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1875 - loss: 2.8971 - val_accuracy: 0.1000 - val_loss: 2.9977\n","Epoch 5/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.1048 - loss: 2.8882 - val_accuracy: 0.1328 - val_loss: 2.8652\n","Epoch 6/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.1875 - loss: 2.7400 - val_accuracy: 0.2500 - val_loss: 2.5999\n","Epoch 7/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.1746 - loss: 2.7130 - val_accuracy: 0.2109 - val_loss: 2.5768\n","Epoch 8/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1250 - loss: 2.9511 - val_accuracy: 0.1500 - val_loss: 2.5182\n","Epoch 9/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.2407 - loss: 2.5632 - val_accuracy: 0.2500 - val_loss: 2.4445\n","Epoch 10/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1250 - loss: 2.8559 - val_accuracy: 0.2000 - val_loss: 2.5937\n","Epoch 11/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.2336 - loss: 2.5001 - val_accuracy: 0.2422 - val_loss: 2.3365\n","Epoch 12/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2500 - loss: 2.5637 - val_accuracy: 0.0500 - val_loss: 2.4773\n","Epoch 13/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.2356 - loss: 2.4204 - val_accuracy: 0.2969 - val_loss: 2.2536\n","Epoch 14/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.2188 - loss: 2.2087 - val_accuracy: 0.4000 - val_loss: 2.0431\n","Epoch 15/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.3037 - loss: 2.2227 - val_accuracy: 0.3672 - val_loss: 2.0816\n","Epoch 16/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.4688 - loss: 2.0185 - val_accuracy: 0.3000 - val_loss: 2.0869\n","Epoch 17/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.3469 - loss: 2.0961 - val_accuracy: 0.3516 - val_loss: 2.1348\n","Epoch 18/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2812 - loss: 2.4368 - val_accuracy: 0.4000 - val_loss: 1.8711\n","Epoch 19/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.3116 - loss: 2.1538 - val_accuracy: 0.3594 - val_loss: 2.1425\n","Epoch 20/20\n","\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3125 - loss: 2.0818 - val_accuracy: 0.2500 - val_loss: 2.2058\n"]}]},{"cell_type":"code","source":["# Evaluasi model\n","test_loss, test_acc = model.evaluate(test_generator)\n","print(f'Test accuracy: {test_acc}')"],"metadata":{"id":"YFIqlx40iypI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732615940005,"user_tz":-420,"elapsed":12174,"user":{"displayName":"Muhammad Nurkholis M183B4KY2981","userId":"05209614594039969122"}},"outputId":"1ecdccd5-4901-4dc5-9ac1-f561995352d9"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.3309 - loss: 2.1366\n","Test accuracy: 0.3378378450870514\n"]}]},{"cell_type":"code","source":["# Melakukan prediksi\n","from google.colab import files\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  img_path = fn\n","\n","img = image.load_img(img_path, target_size=(100, 100))\n","img_array = image.img_to_array(img)\n","img_array = np.expand_dims(img_array, axis=0)\n","img_array /= 255.0\n","\n","predictions = model.predict(img_array)\n","\n","# Get the predicted class index\n","predicted_class_index = np.argmax(predictions)\n","\n","# Get the class labels (assuming you have them in train_data.class_indices)\n","class_labels = list(train_generator.class_indices.keys())\n","\n","# Print the predicted class label\n","predicted_class_label = class_labels[predicted_class_index]\n","print(\"Predicted Class:\", predicted_class_label)"],"metadata":{"id":"v25nf-x3jeBR","colab":{"base_uri":"https://localhost:8080/","height":109},"executionInfo":{"status":"ok","timestamp":1732616027030,"user_tz":-420,"elapsed":14664,"user":{"displayName":"Muhammad Nurkholis M183B4KY2981","userId":"05209614594039969122"}},"outputId":"dd59deb5-9b93-43ec-cff5-030ed5c34130"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-d1a7ab7e-2490-4162-b91e-7028b702107a\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-d1a7ab7e-2490-4162-b91e-7028b702107a\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving anggur_test (4).jpg to anggur_test (4).jpg\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n","Predicted Class: anggur\n"]}]},{"cell_type":"code","source":["# Melakukan prediksi\n","from google.colab import files\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  img_path = fn\n","\n","img = image.load_img(img_path, target_size=(100, 100))\n","img_array = image.img_to_array(img)\n","img_array = np.expand_dims(img_array, axis=0)\n","img_array /= 255.0\n","\n","predictions = model.predict(img_array)\n","\n","# Get the predicted class index\n","predicted_class_index = np.argmax(predictions)\n","\n","# Get the class labels (assuming you have them in train_data.class_indices)\n","class_labels = list(train_generator.class_indices.keys())\n","\n","# Print the predicted class label\n","predicted_class_label = class_labels[predicted_class_index]\n","print(\"Predicted Class:\", predicted_class_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"uvCCSteyNCJH","executionInfo":{"status":"ok","timestamp":1732616084920,"user_tz":-420,"elapsed":10288,"user":{"displayName":"Muhammad Nurkholis M183B4KY2981","userId":"05209614594039969122"}},"outputId":"e983a192-5b5b-4165-8f46-d4fe6757ee6f"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-6e981d75-5281-458a-9762-0c32385f3a99\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-6e981d75-5281-458a-9762-0c32385f3a99\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving bubur_test (3).jpg to bubur_test (3).jpg\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","Predicted Class: kerupuk\n"]}]},{"cell_type":"code","source":["# Menyimpan model\n","model.save('model_makanan.h5')"],"metadata":{"id":"I-Ge81YRNC1P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732616093951,"user_tz":-420,"elapsed":312,"user":{"displayName":"Muhammad Nurkholis M183B4KY2981","userId":"05209614594039969122"}},"outputId":"23c628a7-ccbc-403d-e262-46f7f61445cf"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}]},{"cell_type":"code","source":["!cp model_makanan.h5 /content/drive/MyDrive/cnnmakananbayi/"],"metadata":{"id":"E4TDCxQ5-Q7O","executionInfo":{"status":"ok","timestamp":1732616232758,"user_tz":-420,"elapsed":303,"user":{"displayName":"Muhammad Nurkholis M183B4KY2981","userId":"05209614594039969122"}}},"execution_count":18,"outputs":[]}]}